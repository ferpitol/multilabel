{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilabel and Multiclass datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primero importamos todas las librerias que necesitaremos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from skmultilearn.problem_transform import BinaryRelevance,ClassifierChain,LabelPowerset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import scipy\n",
    "from scipy.io import arff\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ahora cargaremos en un array todos los metodos que usaremos para clasificar nuestro problema, un paso comun es usar los algoritmos mas conocidos en sus formas basicas y ver cual es el que se comporta mejor con nuestro dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "    KNeighborsClassifier(20),\n",
    "    SVC(kernel=\"linear\", C=0.06),\n",
    "    SVC(gamma=2, C=1),\n",
    "    #GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "    DecisionTreeClassifier(max_depth=22),\n",
    "    RandomForestClassifier(max_depth=22, n_estimators=10, max_features=1),\n",
    "    MLPClassifier(alpha=1),\n",
    "    AdaBoostClassifier(n_estimators=10),\n",
    "    GaussianNB()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ahora crearemos una funcion que recibira un clasificador 'x' , datos de entrenamiento asi como de testeo testeo y nos regresara su desempeño"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_classifications(classifier,X_train, y_train,X_test,y_test):\n",
    "    classifier.fit(X_train, y_train)\n",
    "    predictions = classifier.predict(X_test)\n",
    "    return accuracy_score(y_test,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ahora carguemos nuestro dataset y examinemoslo, este dataset se encuentra en : \n",
    "https://archive.ics.uci.edu/ml/datasets/Anuran+Calls+%28MFCCs%29\n",
    "Básicamente el dataset tiene 22 campos numericos que representan mediciones del sonido que hacen algunas especies de ranas, dicho dataset tiene tres categorias a clasificar : Families, Genus y Species, cada una de estas, asu vez, es una multiclase y sus datos son:\n",
    "\n",
    "__Families__                  \n",
    "- Bufonidae               \n",
    "- Dendrobatidae           \n",
    "- Hylidae \n",
    "- Leptodactylidae\n",
    "\n",
    "__Genus__\n",
    "- Adenomera \n",
    "- Ameerega\n",
    "- Dendropsophus \n",
    "- Hypsiboas \n",
    "- Leptodactylus \n",
    "- Osteocephalus \n",
    "- Rhinella \n",
    "- Scinax\n",
    "\n",
    "__Species__\n",
    "- AdenomeraAndre \n",
    "- AdenomeraHylaedact \n",
    "- Ameeregatrivittata \n",
    "- HylaMinuta \n",
    "- HypsiboasCinerascens \n",
    "- HypsiboasCordobae \n",
    "- LeptodactylusFuscus \n",
    "- OsteocephalusOopha \n",
    "- Rhinellagranulosa \n",
    "- ScinaxRuber\n",
    "\n",
    "Y es aqui donde las cosas se vuelven interesantes, para una misma entrada tendremos un tipo de familie, genus y Species y no solo eso, cada una de esta categorias es multiclass, entonces ¿como trabajamos con estos datasets?, bueno primero sera ver el dataset: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   MFCCs_ 1  MFCCs_ 2  MFCCs_ 3  MFCCs_ 4  MFCCs_ 5  MFCCs_ 6  MFCCs_ 7  \\\n",
      "0       1.0  0.152936 -0.105586  0.200722  0.317201  0.260764  0.100945   \n",
      "1       1.0  0.171534 -0.098975  0.268425  0.338672  0.268353  0.060835   \n",
      "2       1.0  0.152317 -0.082973  0.287128  0.276014  0.189867  0.008714   \n",
      "3       1.0  0.224392  0.118985  0.329432  0.372088  0.361005  0.015501   \n",
      "4       1.0  0.087817 -0.068345  0.306967  0.330923  0.249144  0.006884   \n",
      "\n",
      "   MFCCs_ 8  MFCCs_ 9  MFCCs_10    ...     MFCCs_17  MFCCs_18  MFCCs_19  \\\n",
      "0 -0.150063 -0.171128  0.124676    ...    -0.108351 -0.077623 -0.009568   \n",
      "1 -0.222475 -0.207693  0.170883    ...    -0.090974 -0.056510 -0.035303   \n",
      "2 -0.242234 -0.219153  0.232538    ...    -0.050691 -0.023590 -0.066722   \n",
      "3 -0.194347 -0.098181  0.270375    ...    -0.136009 -0.177037 -0.130498   \n",
      "4 -0.265423 -0.172700  0.266434    ...    -0.048885 -0.053074 -0.088550   \n",
      "\n",
      "   MFCCs_20  MFCCs_21  MFCCs_22           Family      Genus         Species  \\\n",
      "0  0.057684  0.118680  0.014038  Leptodactylidae  Adenomera  AdenomeraAndre   \n",
      "1  0.020140  0.082263  0.029056  Leptodactylidae  Adenomera  AdenomeraAndre   \n",
      "2 -0.025083  0.099108  0.077162  Leptodactylidae  Adenomera  AdenomeraAndre   \n",
      "3 -0.054766 -0.018691  0.023954  Leptodactylidae  Adenomera  AdenomeraAndre   \n",
      "4 -0.031346  0.108610  0.079244  Leptodactylidae  Adenomera  AdenomeraAndre   \n",
      "\n",
      "   RecordID  \n",
      "0         1  \n",
      "1         1  \n",
      "2         1  \n",
      "3         1  \n",
      "4         1  \n",
      "\n",
      "[5 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"frogs/Frogs_MFCCs.csv\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7195 entries, 0 to 7194\n",
      "Data columns (total 26 columns):\n",
      "MFCCs_ 1    7195 non-null float64\n",
      "MFCCs_ 2    7195 non-null float64\n",
      "MFCCs_ 3    7195 non-null float64\n",
      "MFCCs_ 4    7195 non-null float64\n",
      "MFCCs_ 5    7195 non-null float64\n",
      "MFCCs_ 6    7195 non-null float64\n",
      "MFCCs_ 7    7195 non-null float64\n",
      "MFCCs_ 8    7195 non-null float64\n",
      "MFCCs_ 9    7195 non-null float64\n",
      "MFCCs_10    7195 non-null float64\n",
      "MFCCs_11    7195 non-null float64\n",
      "MFCCs_12    7195 non-null float64\n",
      "MFCCs_13    7195 non-null float64\n",
      "MFCCs_14    7195 non-null float64\n",
      "MFCCs_15    7195 non-null float64\n",
      "MFCCs_16    7195 non-null float64\n",
      "MFCCs_17    7195 non-null float64\n",
      "MFCCs_18    7195 non-null float64\n",
      "MFCCs_19    7195 non-null float64\n",
      "MFCCs_20    7195 non-null float64\n",
      "MFCCs_21    7195 non-null float64\n",
      "MFCCs_22    7195 non-null float64\n",
      "Family      7195 non-null object\n",
      "Genus       7195 non-null object\n",
      "Species     7195 non-null object\n",
      "RecordID    7195 non-null int64\n",
      "dtypes: float64(22), int64(1), object(3)\n",
      "memory usage: 1.4+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          MFCCs_ 1     MFCCs_ 2     MFCCs_ 3     MFCCs_ 4     MFCCs_ 5  \\\n",
      "count  7195.000000  7195.000000  7195.000000  7195.000000  7195.000000   \n",
      "mean      0.989885     0.323584     0.311224     0.445997     0.127046   \n",
      "std       0.069016     0.218653     0.263527     0.160328     0.162722   \n",
      "min      -0.251179    -0.673025    -0.436028    -0.472676    -0.636012   \n",
      "25%       1.000000     0.165945     0.138445     0.336737     0.051717   \n",
      "50%       1.000000     0.302184     0.274626     0.481463     0.161361   \n",
      "75%       1.000000     0.466566     0.430695     0.559861     0.222592   \n",
      "max       1.000000     1.000000     1.000000     1.000000     0.752246   \n",
      "\n",
      "          MFCCs_ 6     MFCCs_ 7     MFCCs_ 8     MFCCs_ 9     MFCCs_10  \\\n",
      "count  7195.000000  7195.000000  7195.000000  7195.000000  7195.000000   \n",
      "mean      0.097939    -0.001397    -0.000370     0.128213     0.055998   \n",
      "std       0.120412     0.171404     0.116302     0.179008     0.127099   \n",
      "min      -0.410417    -0.538982    -0.576506    -0.587313    -0.952266   \n",
      "25%       0.012581    -0.125737    -0.063109     0.004648    -0.001132   \n",
      "50%       0.072079    -0.052630     0.013265     0.189317     0.063478   \n",
      "75%       0.175957     0.085580     0.075108     0.265395     0.117725   \n",
      "max       0.964240     1.000000     0.551762     0.738033     0.522768   \n",
      "\n",
      "          ...          MFCCs_14     MFCCs_15     MFCCs_16     MFCCs_17  \\\n",
      "count     ...       7195.000000  7195.000000  7195.000000  7195.000000   \n",
      "mean      ...         -0.039244    -0.101748     0.042062     0.088680   \n",
      "std       ...          0.152515     0.187618     0.119915     0.138055   \n",
      "min       ...         -0.590380    -0.717156    -0.498675    -0.421480   \n",
      "25%       ...         -0.132980    -0.255929    -0.019549    -0.001764   \n",
      "50%       ...         -0.050715    -0.143259     0.041081     0.112769   \n",
      "75%       ...          0.039157     0.017348     0.107046     0.201932   \n",
      "max       ...          0.575749     0.668924     0.670700     0.681157   \n",
      "\n",
      "          MFCCs_18     MFCCs_19     MFCCs_20     MFCCs_21     MFCCs_22  \\\n",
      "count  7195.000000  7195.000000  7195.000000  7195.000000  7195.000000   \n",
      "mean      0.007755    -0.049474    -0.053244     0.037313     0.087567   \n",
      "std       0.084733     0.082546     0.094181     0.079470     0.123442   \n",
      "min      -0.759322    -0.680745    -0.361649    -0.430812    -0.379304   \n",
      "25%      -0.042122    -0.106079    -0.120971    -0.017620     0.000533   \n",
      "50%       0.011820    -0.052626    -0.055180     0.031274     0.105373   \n",
      "75%       0.061889     0.006321     0.001342     0.089619     0.194819   \n",
      "max       0.614064     0.574209     0.467831     0.389797     0.432207   \n",
      "\n",
      "          RecordID  \n",
      "count  7195.000000  \n",
      "mean     25.220014  \n",
      "std      13.214399  \n",
      "min       1.000000  \n",
      "25%      15.000000  \n",
      "50%      22.000000  \n",
      "75%      37.000000  \n",
      "max      60.000000  \n",
      "\n",
      "[8 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ahora que ya conocemos al enemigo, prosigamos a limpiarlo, el unico problema que parece tener este dataset es que sus clases son objetos del tipo object, en este caso son textos, asi que prosigamos a volverlos del tipo categorias para mejorar el performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"Family\",\"Genus\",\"Species\"]] = df[[\"Family\",\"Genus\",\"Species\"]].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bien, el siguiente paso sera convertir cada clase en una columna binaria para que los algoritmos puedan funcionar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Leptodactylidae\n",
      "1    Leptodactylidae\n",
      "2    Leptodactylidae\n",
      "3    Leptodactylidae\n",
      "4    Leptodactylidae\n",
      "Name: Family, dtype: category\n",
      "Categories (4, object): [Bufonidae, Dendrobatidae, Hylidae, Leptodactylidae]\n",
      "   Bufonidae  Dendrobatidae  Hylidae  Leptodactylidae\n",
      "0          0              0        0                1\n",
      "1          0              0        0                1\n",
      "2          0              0        0                1\n",
      "3          0              0        0                1\n",
      "4          0              0        0                1\n"
     ]
    }
   ],
   "source": [
    "print(df[\"Family\"].head())\n",
    "\n",
    "dfFamily =  pd.get_dummies(df[\"Family\"])\n",
    "\n",
    "print(dfFamily.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Y lo mismo con las otras dos clases "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfGenus =  pd.get_dummies(df[\"Genus\"])\n",
    "dfSpecies =  pd.get_dummies(df[\"Species\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenamos los dataframes: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft = pd.concat([df[df.columns[0:22]],dfFamily,dfGenus,dfSpecies],axis=\"columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separemos en dos dataframes el dataframe original, a decir, uno que represente los datos y otro las clases "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df[df.columns[0:22]]\n",
    "classes = dft[[\"Adenomera\",\"AdenomeraAndre\",\"AdenomeraHylaedactylus\",\"Ameerega\",\"Ameeregatrivittata\",\n",
    "               \"Bufonidae\",\"Dendrobatidae\",\"Dendropsophus\",\"HylaMinuta\",\"Hylidae\",\"Hypsiboas\",\n",
    "               \"HypsiboasCinerascens\",\"HypsiboasCordobae\",\"Leptodactylidae\",\"Leptodactylus\",\n",
    "               \"LeptodactylusFuscus\",\"Osteocephalus\",\"OsteocephalusOophagus\",\"Rhinella\",\"Rhinellagranulosa\",\n",
    "               \"Scinax\",\"ScinaxRuber\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ahora generemos los conjuntos de entramiento y testeo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, classes, test_size=0.30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listo y ¿ahora qué?, bueno, no podemos usar cualquier algoritmo aqui por que fallaria estrepitosamente, ya que tenemos un problema de multilabel, es decir, tenemos que clasificar aqui tres clases en vez de una, veamos un ejemplo de como fallaria cualquier algoritmo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "bad input shape (5036, 22)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-397bdc103a83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_classifications\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"linear\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.06\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-e30e2f71207e>\u001b[0m in \u001b[0;36mmake_classifications\u001b[0;34m(classifier, X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmake_classifications\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msparse\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'C'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    576\u001b[0m                         dtype=None)\n\u001b[1;32m    577\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m         \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_numeric\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'O'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcolumn_or_1d\u001b[0;34m(y, warn)\u001b[0m\n\u001b[1;32m    612\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 614\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bad input shape {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: bad input shape (5036, 22)"
     ]
    }
   ],
   "source": [
    "acc = make_classifications(SVC(kernel=\"linear\", C=0.06),X_train, y_train,X_test,y_test)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### entonces que hacemos, bueno tenemos tres formas de enfrentarnos a estos problemas:\n",
    "\n",
    "- Binary Relevance\n",
    "- Classifier Chains\n",
    "- Label Powerset\n",
    "\n",
    "y basicamente hacen esto:\n",
    "\n",
    "__Binary Relevance__:\n",
    "    este es el divide y venceras, basicamente toma cada posible clase individualmente y la clasifica, luego concatena todo y obtiene el resultado:\n",
    "\n",
    "Original   \n",
    "<img src=\"example1.png\">\n",
    "Lo convierte en:\n",
    "<img src=\"example2.png\">\n",
    "\n",
    "\n",
    "__Classifier Chains__\n",
    "    En esta tecnica primero toma solo una columna de clase y la clasifica, luego toma otra columna de clase para clasificarla pero la primera formara parte de los datos , luego tomara una tercera y las dos primeras formaran parte de los datos, mmm una imagen muestra mejor este proceso\n",
    "\n",
    "Original   \n",
    "<img src=\"example1.png\">\n",
    "Lo convierte en:\n",
    "<img src=\"example3.png\">\n",
    "Los datos sombreados en amarillo son los que usariamos para clasificar nuestra clase\n",
    "\n",
    "__Label Powerset__\n",
    "    A mi parecer el mas sencillo de entender, aqui intentamos etiquetar las diferentes condiciones en que se generan las clases y creamos clases nuevas\n",
    "\n",
    "Original   \n",
    "<img src=\"example4.png\">\n",
    "Lo convierte en:\n",
    "<img src=\"example5.png\">\n",
    "  este metodo es el mas simple, sin embargo, cabe mencionar que requeririamos de tener todas las posibles combinaciones para generar todas las clases posibles\n",
    "\n",
    "\n",
    "Que metodo es mejor, bueno sinceramente es mejor experimentar todos los casos para ver cual se acomoda a nuestro problema, para python tenemos que la libreria skmultilearn.problem_transform nos regala estos metodos, entonces manos a la obra\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary technique---------------------------------------------------------------------\n",
      "[0.9569245020842982, 0.667901806391848, 0.9722093561834182, 0.8503937007874016, 0.8786475220009263, 0.8235294117647058, 0.8022232515053266, 0.50764242704956]\n",
      "Chain technique----------------------------------------------------------------------\n",
      "[0.9647985178323297, 0.8809634089856415, 0.9814729041222788, 0.9198703103288559, 0.9249652616952293, 0.8971746178786475, 0.9129226493747105, 0.5673923112552107]\n",
      "Label power technique----------------------------------------------------------------\n",
      "[0.9629458082445577, 0.9096804075961094, 0.9874942102825383, 0.9421028253821213, 0.9675775822139879, 0.9217230199166281, 0.7401574803149606, 0.9096804075961094]\n"
     ]
    }
   ],
   "source": [
    "print(\"Binary technique---------------------------------------------------------------------\")\n",
    "results = [make_classifications(BinaryRelevance(classifier),X_train, y_train,X_test,y_test) \n",
    "           for classifier in classifiers]\n",
    "print(results)\n",
    "\n",
    "print(\"Chain technique----------------------------------------------------------------------\")\n",
    "results = [make_classifications(ClassifierChain(classifier),X_train, y_train,X_test,y_test) \n",
    "           for classifier in classifiers]\n",
    "print(results)\n",
    "\n",
    "print(\"Label power technique----------------------------------------------------------------\")\n",
    "results = [make_classifications(LabelPowerset(classifier),X_train, y_train,X_test,y_test) \n",
    "           for classifier in classifiers]\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Como observamos , al menos para este datasets, las tecnicas que mejor se comportaron fueron Chain y label, ya aqui es cuestion, dependiendo de nuestro problema tomar una desicion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
